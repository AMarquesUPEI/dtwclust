\documentclass[article,shortnames,nojss]{jss}

% Vignette options
%\VignetteEngine{knitr::knitr}
%\VignettePackage{dtwclust}
%\VignetteIndexEntry{Comparing Time Series Clustering Algorithms in R Using the dtwclust Package}
%\VignetteEncoding{UTF-8}

% Maths
\usepackage{amsmath}

% Captions in floating environments
\usepackage[labelsep=colon,font=small,margin=5pt,format=hang]{caption}

% For subcaptions in figures
\usepackage{subcaption}

% For professional looking tables
\usepackage{booktabs}
%\usepackage{multirow}
%\usepackage{multicol}
%\usepackage{longtable}
%\usepackage{tabularx}

% For \FloatBarrier
\usepackage[section,below]{placeins}

% Linebreaks in tables
\usepackage{makecell}

% References
\usepackage[capitalise]{cleveref}

% Used for knitr images from Rnw files
\newcommand{\subfloat}[2][default for first parameter: need a sub-caption]{\subcaptionbox{#1}{#2}}

% Shortcuts
\newcommand{\R}{\proglang{R}}
\newcommand{\dtwclust}{\pkg{dtwclust}}

% ===========================================================================================================
% Cover
% ===========================================================================================================

\title{Comparing Time Series Clustering Algorithms in \R{} Using the \dtwclust{} Package}
\Plaintitle{Comparing Time Series Clustering Algorithms in R Using the dtwclust Package}

\author{Alexis~Sard\'a-Espinosa}
\date{\today}

\Address{
Alexis Sard\'a-Espinosa\\
\email{alexis.sarda@gmail.com}
}

\Abstract{
Abstract
}

\Keywords{time series, clustering, \R{}, dynamic time warping}
\Plainkeywords{time series, clustering, R, dynamic time warping}

% ===========================================================================================================
% Main matter
% ===========================================================================================================

\begin{document}

<<setup, include = FALSE, cache = FALSE>>=
library(knitr)
library(dtwclust)

# knitr defaults
opts_chunk$set(fig.width = 12, fig.asp = 0.5625,
               out.width = "\\linewidth",
               fig.align = "center", fig.pos = "hbp",
               cache = TRUE, echo = FALSE, autodep = TRUE)
@


\section{Introduction}
\label{sec:introduction}

Cluster analysis is a general task which concerns itself with the creation of groups of objects, where each group is called a cluster. Ideally, all members of the same cluster are similar to each other, but are as dissilimar as possible from objects in a different cluster. There is no single definition of a cluster, and the characteristics of the objects to be clustered varies. Thus, there are several algorithms to perform clustering. Each one defines specific ways of defining what a cluster is, how to measure similarities, how to find groups efficiently, etc. Additionally, each application might have different goals, so a certain clustering algorithm may be preferred depending on the type of clusters sought \citep{kaufman1990}.

Clustering algorithms can be organized differently depending on how they handle the data and how the groups are created. When it comes to static data, i.e. if the values do not change with time \citep{liao2005}, clustering methods are usually divided into five major categories: \textbf{partitioning (or partitional)}, \textbf{hierarchical}, \textbf{density-based}, \textbf{grid-based} and \textbf{model-based} methods \citep{liao2005, rani2012}. They may be used as the main algorithm, as an intermediate step, or as a preprocessing step \citep{aghabozorgi2015}.

Time-series are a common type of dynamic data that naturally arises in many different scenarios, such as stock data, medical data, and machine monitoring, just to name a few \citep{aghabozorgi2015, aggarwal2013}. They pose some challenging issues due to the large size and high dimensionality commonly associated with time-series \citep{aghabozorgi2015}. In this context, dimensionality of a series is related to time, and it can be understood as the length of the series. Additionally, a single time-series object may be constituted of several values that change on the same time scale, in which case they are identified as multivariate time series.

There are many techniques to modify time series in order to reduce dimensionality, and they mostly deal with the way time-series are represented. Changing representation can be an important step, not only in time-series clustering, and it constitutes a wide research area on its own (cf. Table 2 in \citep{aghabozorgi2015}). While choice of representation can directly affect clustering, it can be considered as a different step, and as such it will not be discussed further in this paper.

Time-series clustering is a type of clustering algorithm made to handle dynamic data. The most important elements to consider are the \textbf{similarity or distance measure}, the \textbf{prototype extraction function} (if applicable), the \textbf{clustering algorithm itself}, and \textbf{cluster evaluation} \citep{aghabozorgi2015}. In most cases, algorithms developed for time-series clustering take static clustering algorithms and either modify the similarity definition or the prototype extraction function by an appropriate one, or apply a transformation to the series so that static features are obtained \citep{liao2005}. Therefore, the underlying basis for the different clustering procedures remains approximately the same across clustering methods. The most common approaches are hierarchcial and partitional clustering (cf. Table 4 in \citep{aghabozorgi2015}), the latter of which includes fuzzy clustering.

\citet{aghabozorgi2015} classify time-series clustering algorithms based on the way they treat the data and how the underlying grouping is performed. One classification depends on whether the \textbf{whole} series, a \textbf{subsequence}, or individual \textbf{time points} are to be clustered. On the other hand, the clustering itself may be \textbf{shape-based}, \textbf{feature-based} or \textbf{model-based}. \citet{aggarwal2013} makes an additional distinction between online and offline approaches, where the former usually deals with grouping incoming data on-the-go, while the latter deals with data that no longer change.

In this context, it is common to change the distance measure for the \textbf{Dynamic Time Warping} (DTW) distance \citep{aghabozorgi2015}. The calculation of the DTW distance involves a dynamic programming algorithm that tries to find the optimum warping path between two series under certain constraints \citep{berndt1994}. However, the DTW algorithm is computationally expensive, both in time and memory utilization. Over the years, several variations and optimizations have been developed in an attempt to accelerate or optimize the calculation. Some of the most common techniques will be discussed in more detail in the next sections.

Due to its nature, clustering procedures lend themselves for parallelization, since a lot of similar calculations are performed independently of each other. This can make a very significant difference, especially if the data complexity increases (which can happen really quickly in case of time-series), or some of the more computationally expensive algorithms are used.

Variations in the clustering procedure could have a big impact in performance with respecto to cluster quality and execution time. As such, it is desirable to have a common platform on which clustering algorithms can be tested and compared against each other. The \dtwclust{} package, developed in the \R{} programming language \citep{rcore}, provides such functionality, and includes implementations of recently developed time-series clustering algorithms and optimizations. Instead of providing a detailed explanation of the existing algorithms, we will concern ourselves with describing which ones are available in \dtwclust{}, mentioning the most important characteristics of each and showing how the package can be used to evaluate them. Additionally, some variations related to DTW and other common distances will be explored, and the parallelization strategies and optimizations will be described. For a more comprehensive overview of the state of the art in time series clustering, the reader is referred to the included references and the articles mentioned therein.

The rest of this paper is organized as follows. The relevant information to the distance measures will be presented in \cref{sec:distances}. Supported algorithms for prototype extraction will be discussed in \cref{sec:prototypes}. The main clustering algorithms will be described in \cref{sec:clustering}. Some basic information with respect to cluster evaluation will be provided in \cref{sec:evaluation}, and the final remarks will be given in \cref{sec:conclusion}.

\section{Distance Measures}
\label{sec:distances}

\section{Time-Series Prototypes}
\label{sec:prototypes}

\section{Time-Series Clustering Algorithms}
\label{sec:clustering}

\section{Cluster Evaluation}
\label{sec:evaluation}

\section{Conclusion}
\label{sec:conclusion}

% ===========================================================================================================
% Bibliography
% ===========================================================================================================

%\bibliographystyle{}
\nocite{*}
\bibliography{REFERENCES}

\end{document}
